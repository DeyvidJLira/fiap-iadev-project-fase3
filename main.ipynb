{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05a02c2fb10643b0b145229fe5195189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ccc31ff9f2f247c295fbcf89cb5b48ac",
            "placeholder": "Digite sua pergunta aqui (em inglês)...",
            "rows": null,
            "style": "IPY_MODEL_df81825e07494b3ca0505127d24b3ea9",
            "value": "Tell me about \"Mog's Kittens\""
          }
        },
        "ccc31ff9f2f247c295fbcf89cb5b48ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "df81825e07494b3ca0505127d24b3ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "511c5ce55b3d4e36adf8b3b134bc71e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Answer:",
            "description_tooltip": null,
            "disabled": true,
            "layout": "IPY_MODEL_4df071b8a2d048ea97c28122fdcecafc",
            "placeholder": "​",
            "rows": null,
            "style": "IPY_MODEL_81abd4641d8744a08f23bfe7d89c818e",
            "value": "\"Mog's Kittens\" are sturdy board books for infants and toddlers (6 months-2 years), featuring simple text and bright pictures of the popular Mog the Cat.\n\n"
          }
        },
        "4df071b8a2d048ea97c28122fdcecafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "100px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": "100px",
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "81abd4641d8744a08f23bfe7d89c818e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab6cbfa3dc524cddbea4a6080509fd66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Enviar",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b989eed286de40cfaca61987f1653db3",
            "style": "IPY_MODEL_373feb136b2e4ebcb0054261c76fdd34",
            "tooltip": ""
          }
        },
        "b989eed286de40cfaca61987f1653db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373feb136b2e4ebcb0054261c76fdd34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "987922f6ee82405a85cfb3aa002c846a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Limpar prompt",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ac58aceeaf7d4b6785d31e873394203c",
            "style": "IPY_MODEL_999b53b014a348b8b432b0e76c7cd1da",
            "tooltip": ""
          }
        },
        "ac58aceeaf7d4b6785d31e873394203c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999b53b014a348b8b432b0e76c7cd1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Orientações gerais e informativos\n",
        "\n",
        "### Secrets utilizados:\n",
        "*   **HF_TOHEN** => Token do HuggingFace;\n",
        "*   **GEMINI_API_KEY** => API KEY do Gemini.\n",
        "\n",
        "### Contexto\n",
        "\n",
        "Derivado do dataset \"The AmazonTitles-1.3MM\", a solução usaram um foundation model para:\n",
        "- Receber perguntas com um contexto obtido por meio do arquivo \"trn.json\" que está contido dentro do dataset;\n",
        "- A partir do prompt formado pela pergunta do usuário sobre o título do produdo, o modelo deverá gerar uma resposta baseada na pergunta do usuário trazendo como resultado do aprenzidado do fine-tuning os dados da sua descrição."
      ],
      "metadata": {
        "id": "i1wdwcSOZcJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passo 0: Configuração"
      ],
      "metadata": {
        "id": "t3GocZGMBege"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação das dependências"
      ],
      "metadata": {
        "id": "vGMn9rCF2nOh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d-ZOTeUm2ENJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbbcc1e2-a70a-4ac1-a7c5-49e68fd0da4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install chromadb --quiet\n",
        "#%pip install sentence-transformers --quiet\n",
        "#%pip install -q -U google-generativeai --quiet\n",
        "#%pip install transformers --quiet\n",
        "#%pip install accelerate --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download do CSV que será utilizado\n",
        "\n",
        "Aqui há 3 possibilidades, a razão disso é que como a quantidade de registros é muito grande, foi gerado CSV de subconjunto desses registros:\n",
        "\n",
        "\n",
        "*   Short: 10.000 registros;\n",
        "*   Medium: 90.000 registros;\n",
        "*   Full: 1.390.138 registros."
      ],
      "metadata": {
        "id": "76pBPtEzSnm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from enum import Enum\n",
        "\n",
        "class SizeData(Enum):\n",
        "  SHORT = 1\n",
        "  MEDIUM = 2\n",
        "  FULL = 3\n",
        "\n",
        "\n",
        "def download_csv(size_data: SizeData = SizeData.SHORT):\n",
        "  if not Path('data/processed_data.csv').is_file():\n",
        "    !mkdir data\n",
        "    %cd data\n",
        "    match(size_data):\n",
        "      case SizeData.SHORT:\n",
        "        !wget 'https://huggingface.co/datasets/DeyvidJLira/desafio-fiap-fase-3/resolve/main/processed_data_10000_rows.csv' -O processed_data.csv\n",
        "      case SizeData.MEDIUM:\n",
        "        !wget 'https://huggingface.co/datasets/DeyvidJLira/desafio-fiap-fase-3/resolve/main/processed_data_90000_rows.csv' -O processed_data.csv\n",
        "      case SizeData.FULL:\n",
        "        !wget 'https://huggingface.co/datasets/DeyvidJLira/desafio-fiap-fase-3/resolve/main/processed_data_1390138_rows.csv' -O processed_data.csv\n",
        "    %cd ..\n",
        "  else:\n",
        "    print(\"Arquivo já existe\")\n",
        "\n",
        "download_csv(size_data=SizeData.SHORT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnKe1TvESwJQ",
        "outputId": "ba30d8dc-2062-4d44-8f9c-9d97b4bb6ef1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "--2024-11-25 19:08:55--  https://huggingface.co/datasets/DeyvidJLira/desafio-fiap-fase-3/resolve/main/processed_data_10000_rows.csv\n",
            "Resolving huggingface.co (huggingface.co)... 65.8.243.92, 65.8.243.46, 65.8.243.90, ...\n",
            "Connecting to huggingface.co (huggingface.co)|65.8.243.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/5b/ff/5bff399b96df2ff2e73b982b28f65cf1a5326a795a84d35495208d4eaa30ffd9/3b32388b58065a215dc53da4bd13163208cbceb12067ab87a603008ec96629b2?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27processed_data_10000_rows.csv%3B+filename%3D%22processed_data_10000_rows.csv%22%3B&response-content-type=text%2Fcsv&Expires=1732820935&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjgyMDkzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzViL2ZmLzViZmYzOTliOTZkZjJmZjJlNzNiOTgyYjI4ZjY1Y2YxYTUzMjZhNzk1YTg0ZDM1NDk1MjA4ZDRlYWEzMGZmZDkvM2IzMjM4OGI1ODA2NWEyMTVkYzUzZGE0YmQxMzE2MzIwOGNiY2ViMTIwNjdhYjg3YTYwMzAwOGVjOTY2MjliMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=tRdlieMUSYRDSVXA-Uv2xD-fEy3mim3W9Js4L8Ah8smJV88bE-XPz3DmC-xFZGJDEo9XW5Ks4quukhQQK05ccGGn6LwVaC-45r-YIgXtpW46SYX-g64aogdNBKv3NT%7EXiGUUXNOLS4%7E8zt2xLE3aKEeeIbso3QyuMGNAzOVOZdMUwWzdBu4hztCpPXHS6k8IWCsTdcDaSAIXEgsALW6uiotajptbXF7kF4wsnlw0SEqXQ5c5YADHdWBuV6QmdAoqaYEvnOCJWMKPsOuGOap7gul8v4Z0OKfTy2x2Cqh8kqMSIb3UmKqIFLw83tJf8qeent0-RCT9zinwwYL3fIUF3g__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2024-11-25 19:08:55--  https://cdn-lfs-us-1.hf.co/repos/5b/ff/5bff399b96df2ff2e73b982b28f65cf1a5326a795a84d35495208d4eaa30ffd9/3b32388b58065a215dc53da4bd13163208cbceb12067ab87a603008ec96629b2?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27processed_data_10000_rows.csv%3B+filename%3D%22processed_data_10000_rows.csv%22%3B&response-content-type=text%2Fcsv&Expires=1732820935&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjgyMDkzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzViL2ZmLzViZmYzOTliOTZkZjJmZjJlNzNiOTgyYjI4ZjY1Y2YxYTUzMjZhNzk1YTg0ZDM1NDk1MjA4ZDRlYWEzMGZmZDkvM2IzMjM4OGI1ODA2NWEyMTVkYzUzZGE0YmQxMzE2MzIwOGNiY2ViMTIwNjdhYjg3YTYwMzAwOGVjOTY2MjliMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=tRdlieMUSYRDSVXA-Uv2xD-fEy3mim3W9Js4L8Ah8smJV88bE-XPz3DmC-xFZGJDEo9XW5Ks4quukhQQK05ccGGn6LwVaC-45r-YIgXtpW46SYX-g64aogdNBKv3NT%7EXiGUUXNOLS4%7E8zt2xLE3aKEeeIbso3QyuMGNAzOVOZdMUwWzdBu4hztCpPXHS6k8IWCsTdcDaSAIXEgsALW6uiotajptbXF7kF4wsnlw0SEqXQ5c5YADHdWBuV6QmdAoqaYEvnOCJWMKPsOuGOap7gul8v4Z0OKfTy2x2Cqh8kqMSIb3UmKqIFLw83tJf8qeent0-RCT9zinwwYL3fIUF3g__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.238.176.91, 18.238.176.83, 18.238.176.56, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.238.176.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10627691 (10M) [text/csv]\n",
            "Saving to: ‘processed_data.csv’\n",
            "\n",
            "processed_data.csv  100%[===================>]  10.13M  38.3MB/s    in 0.3s    \n",
            "\n",
            "2024-11-25 19:08:56 (38.3 MB/s) - ‘processed_data.csv’ saved [10627691/10627691]\n",
            "\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "H0pP1N2E2Hz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "import uuid;\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "PzNPVVCF2Krc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7994e2f4-3637-422f-d209-b0636b6ebd57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação das classes Database e Assistants que serão utilizadas durante o projeto\n",
        "\n",
        "Nesta seção você encontrará 3 classes:\n",
        "- Database: reune as operações destinadas ao VectorDB utilizado (ChromaDB);\n",
        "- AssistantGeneric: reune as operações da aplicação que gerará o contexto e usará um módelo que esteja disponível no HugginFace (BERT, GPT e Llama) para construir uma resposta mais assertiva;\n",
        "- AssistantGemini: reune as operações da aplicação que gerará o contexto e usará o Gemini para construir uma resposta mais assertiva.\n",
        "\n",
        "Para o database foi utilizado o modelo de embedding **\"paraphrase-MiniLM-L3-v2\"** por ser mais eficiente para textos curtos. Antes utilizamos **\"all-MiniLM-L6-v2\"**, mas o resultado era ineficiente nas buscas que envolviam títulos com pouco conteúdo.\n",
        "\n",
        "A fim de melhorar a perfomance, para o ChromeDB geramos um contexto e embeddamos ele, isso fez com que o retorno na busca de conteúdo relacionado ao título se torna-se mais precisa."
      ],
      "metadata": {
        "id": "GxQB6mT12PiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Database:\n",
        "    def __init__(self) -> None:\n",
        "        self.client = chromadb.PersistentClient(path=\"./chromadb_data\",\n",
        "                                      settings=Settings(anonymized_telemetry=False))\n",
        "        self.collection = self.client.get_or_create_collection(\"database\")\n",
        "        self.embedding_model = SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
        "\n",
        "\n",
        "    def index_csv_data(self, csv_file, reindex: bool = False):\n",
        "        if(reindex):\n",
        "            self.collection.delete(where={\"all\": True})\n",
        "        elif( self.collection.count() > 2):\n",
        "            print(\"Já existem dados indexados, para uma nova indexação apague o chromadb_data\")\n",
        "            return\n",
        "\n",
        "        df = pd.read_csv(\n",
        "            csv_file,\n",
        "            quotechar='\"',\n",
        "            delimiter=\",\",\n",
        "            encoding=\"utf-8\",\n",
        "            on_bad_lines='warn'\n",
        "        )\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            doc_id = str(uuid.uuid4())\n",
        "\n",
        "            title = row['title']\n",
        "            content = row['content']\n",
        "            context = f'Title: {title}\\nContent: {content}'\n",
        "            embedding = self.embedding_model.encode(context)\n",
        "            self.collection.add(\n",
        "                documents=[content],\n",
        "                metadatas=[{\"title\": title, \"id\": doc_id}],\n",
        "                embeddings=embedding,\n",
        "                ids=[doc_id]\n",
        "            )\n",
        "        print(\"Dados indexados!\")\n",
        "\n",
        "\n",
        "    def query(self, query: str, top_k = 3):\n",
        "        query_embedding = self.embedding_model.encode(query)\n",
        "        return self.collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=top_k\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class AssistantGeneric:\n",
        "    def __init__(self, model_name ) -> None:\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            model_name,\n",
        "            token=userdata.get('HF_TOKEN'))\n",
        "        self.model = AutoModelForCausalLM.from_pretained(\n",
        "            model_name,\n",
        "            token=userdata.get('HF_TOKEN'),\n",
        "            torch_dtype=\"float16\",\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "\n",
        "    def query(self, message: str, db: Database) -> str:\n",
        "        results = db.query(message)\n",
        "        retrieved_docs = results['documents'][0]\n",
        "        retrieved_titles = [doc['title'] for doc in results['metadatas'][0]]\n",
        "\n",
        "        context = \"\\n\\n\".join([f'Title: {retrieved_titles[i]}\\nContent: {retrieved_docs[i]}' for i in range(len(retrieved_docs))])\n",
        "        prompt = f'With the Context: \\n{context}\\n\\nAnswer concisely and accurately the Question: {message}.'\n",
        "\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "        outputs = self.model.generate(inputs.input_ids, max_new_tokens=3)\n",
        "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "class AssistantGemini:\n",
        "    def __init__(self, api_key) -> None:\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel()\n",
        "\n",
        "\n",
        "    def generate_context(self, message: str, db: Database) -> str:\n",
        "        results = db.query(message)\n",
        "        retrieved_docs = results['documents'][0]\n",
        "        retrieved_titles = [doc['title'] for doc in results['metadatas'][0]]\n",
        "\n",
        "        context = \"\\n\\n\".join([f'Title: {retrieved_titles[i]}\\nContent: {retrieved_docs[i]}' for i in range(len(retrieved_docs))])\n",
        "        return context\n",
        "\n",
        "\n",
        "    def query(self, message: str, db: Database) -> str:\n",
        "        results = db.query(message, top_k=10)\n",
        "        retrieved_docs = results['documents'][0]\n",
        "        retrieved_titles = [doc['title'] for doc in results['metadatas'][0]]\n",
        "\n",
        "        context = \"\\n\\n\".join([f'Title: {retrieved_titles[i]}\\nContent: {retrieved_docs[i]}' for i in range(len(retrieved_docs))])\n",
        "        prompt = f'With the Context: \\n{context}\\n\\nAnswer concisely and accurately the Question: {message}.'\n",
        "\n",
        "        response = self.model.generate_content(prompt)\n",
        "        return response.text\n"
      ],
      "metadata": {
        "id": "JD1CaEpF2REO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passo 1: Preparação"
      ],
      "metadata": {
        "id": "K2yW-n4jBxgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Database\n",
        "\n",
        "Os dados eles foram pré processados, onde ocorreu as seguintes operações em cima do \"trn.json\":\n",
        "*   Gerou-se um dataframe;\n",
        "```\n",
        "import json\n",
        "import gzip\n",
        "import pandas as pd\n",
        "```\n",
        "```\n",
        "data = None\n",
        "with gzip.open('trn.json.gz') as f:\n",
        "     data = [json.loads(line) for line in f]\n",
        "```\n",
        "```\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"base_data.csv\", index=False)\n",
        "```\n",
        "*   Removido todos os registros que não tinha conteúdo:\n",
        "```\n",
        "df2 = df.dropna()\n",
        "```\n",
        "*   Removido colunas desnecessárias:\n",
        "```\n",
        "df2 = df2.drop(columns=['target_ind', 'target_rel', 'uid'])\n",
        "```\n",
        "* Dados salvos em CSV:\n",
        "```\n",
        "df2.to_csv('processed_data.csv', index=False)\n",
        "```\n",
        "CSV disponível em: [Vide aqui](https://huggingface.co/datasets/DeyvidJLira/desafio-fiap-fase-3/blob/main/processed_data_1390138_rows.csv)."
      ],
      "metadata": {
        "id": "aBnl9aJD9GlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "database = Database()\n",
        "database.index_csv_data('/content/data/processed_data.csv', reindex=True)"
      ],
      "metadata": {
        "id": "HvC5wMVA27NS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087a9e67-ced9-4d0c-a297-b881c2177f3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados indexados!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare AI Assistant"
      ],
      "metadata": {
        "id": "5iT9lv1x_teQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = AssistantGemini(userdata.get('GEMINI_API_KEY'))"
      ],
      "metadata": {
        "id": "leut0li5_vmQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos ver o total de dados inseridos no banco"
      ],
      "metadata": {
        "id": "kM4pHT1nPnQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total de registros inseridos: {database.collection.count()}')"
      ],
      "metadata": {
        "id": "K8IJqQrZPmEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d72cb3c-b75d-4ce8-e6ca-cd5582e2b492"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de registros inseridos: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simulando como estar a obtenção de contexto"
      ],
      "metadata": {
        "id": "ywy4a-jMPreO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(assistant.generate_context('Tell me about \"Girls Ballet Tutu Neon Blue\"', database))"
      ],
      "metadata": {
        "id": "PsS_aRH9PytZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a1ba4e-5de6-4619-ea87-f1de7bd87cb0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Girls Ballet Tutu Neon Blue\n",
            "Content: Dance tutu for girls ages 2-8 years. Perfect for dance practice, recitals and performances, costumes or just for fun!\n",
            "\n",
            "Title: Girls Ballet Tutu Neon Pink\n",
            "Content: High quality 3 layer ballet tutu. 12 inches in length\n",
            "\n",
            "Title: Ballerina Flying\n",
            "Content: Geared to a younger audience, Alexa Brandenberg's Ballerina Flying brings readers to the narrator's Tuesday ballet class. \"My name is Mina and I love to dance.... But I like ballet dance best of all./ To me, ballet dance is like flying.\" Watercolor vignettes depict her preparations; on double-page spreads, Miss Viola demonstrates positions on the verso page; opposite, her students practice. French pronunciations are provided.Copyright 2002 Cahners Business Information, Inc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passo 2: Carregar Interface de Usuário"
      ],
      "metadata": {
        "id": "EuizamJt7hlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_to_chatbot(question) -> str:\n",
        "    try:\n",
        "      return assistant.query(question, database)\n",
        "    except Exception as e:\n",
        "      return f\"Ocorreu um erro: {e}\"\n",
        "\n",
        "\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "prompt_input = widgets.Textarea(\n",
        "    placeholder=\"Digite sua pergunta aqui (em inglês)...\",\n",
        "    description=\"Prompt:\",\n",
        "    layout=widgets.Layout(width=\"100%\")\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(description=\"Enviar\")\n",
        "clear_prompt_button = widgets.Button(description=\"Limpar prompt\")\n",
        "\n",
        "output_area = widgets.Textarea(\n",
        "    description=\"Answer:\",\n",
        "    disabled=True,\n",
        "    layout=widgets.Layout(\n",
        "        width=\"100%\",\n",
        "        height=\"100px\",\n",
        "        min_height=\"100px\",\n",
        "        overflow=\"auto\"\n",
        "    )\n",
        ")\n",
        "\n",
        "def on_button_click(b):\n",
        "    prompt = prompt_input.value.strip()\n",
        "    if prompt:\n",
        "        output_area.value = \"\"\n",
        "        answer = ask_to_chatbot(prompt)\n",
        "        output_area.value = f\"{answer}\\n\"\n",
        "    else:\n",
        "        output_area.value = \"Prompt é necessário!\"\n",
        "\n",
        "\n",
        "def on_button_clear_prompt_click(b):\n",
        "  prompt_input.value = \"\"\n",
        "\n",
        "\n",
        "generate_button.on_click(on_button_click)\n",
        "clear_prompt_button.on_click(on_button_clear_prompt_click)\n",
        "\n",
        "display(prompt_input, output_area, generate_button, clear_prompt_button)\n",
        "\n"
      ],
      "metadata": {
        "id": "Av4nwRbW8RtF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248,
          "referenced_widgets": [
            "05a02c2fb10643b0b145229fe5195189",
            "ccc31ff9f2f247c295fbcf89cb5b48ac",
            "df81825e07494b3ca0505127d24b3ea9",
            "511c5ce55b3d4e36adf8b3b134bc71e8",
            "4df071b8a2d048ea97c28122fdcecafc",
            "81abd4641d8744a08f23bfe7d89c818e",
            "ab6cbfa3dc524cddbea4a6080509fd66",
            "b989eed286de40cfaca61987f1653db3",
            "373feb136b2e4ebcb0054261c76fdd34",
            "987922f6ee82405a85cfb3aa002c846a",
            "ac58aceeaf7d4b6785d31e873394203c",
            "999b53b014a348b8b432b0e76c7cd1da"
          ]
        },
        "outputId": "8fc5436f-a3e7-42f5-9412-07aa08806628"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Prompt:', layout=Layout(width='100%'), placeholder='Digite sua pergunta aqui (…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05a02c2fb10643b0b145229fe5195189"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Answer:', disabled=True, layout=Layout(height='100px', min_height='100px', ove…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "511c5ce55b3d4e36adf8b3b134bc71e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Enviar', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab6cbfa3dc524cddbea4a6080509fd66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Limpar prompt', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "987922f6ee82405a85cfb3aa002c846a"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}